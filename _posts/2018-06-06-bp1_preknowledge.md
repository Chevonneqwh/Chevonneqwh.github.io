---
layout: post
title: BP神经网络手写体识别（一）预备知识
date: 2018-06-06 
tags: BP神经网络   
---



<!-- 使用MathJax引擎，使得MarkDown被编译到html文件中依然能显示出公式 -->

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script> 

在实现编码之前，让我们先来了解一下图像与BP神经网络吧！

### 1. 图像

**1.1 图像**

- 具体概念：可以看作是对物体或场景的一种表现形式，在人的视觉系统中产生视觉印象的客观对象，如自然景物、建筑、用数学描述的图形等等。 
- 抽象定义：二维函数f(x, y)
  - 几何属性
  - 物理属性

**1.2 数字图像分类**

- 位图：又称为点阵图像，由像素的单个点组成。常见格式有BMP、JPG、GIF等
  - 优点：色彩丰富，形象逼真
  - 缺点：文件较大，缩放和旋转容易失真*（位图被放大，但像素点数量不变，因此图像的分辨率会降低）*
- 矢量图：由矢量数据表示的图像。矢量数据可以是点、线、矩形等。常见格式有PNG、BW、AI等
  - 优点：文件较小，放大、缩小或旋转等操作时不会失真
  - 缺点：不易制作色彩丰富的图像

**1.3 色彩系统介绍**

- 彩色图像

  - 自然界的所有颜色都可以由红、绿、蓝（RGB）三原色组成
  - R、G、B每种颜色各由1Byte描述，即8bit，由此，将3原色分成0-255共256个等级
  - 根据红、绿、蓝各种不同的组合我们可以表示出约1600万种颜色（256×256×256）
  - 当一幅图像中每个像素点被赋予不同的RGB值时，就能形成彩色图像了
  - 对于一幅200×200的彩色图像，一个像素需要3个字节，保存整个图像需要用200×200×3的存储空间，即120000个字节 

- 灰度图像

  - 灰度图就是只含亮度信息，不含色彩信息的图像
  - 要表示灰度图，只需要将亮度值进行量化
    - 量化成0-255共256个等级，0表示最暗（全黑），255表示最亮（全白）
    - 灰度图的RGB每个分量都相同（即只保留一个通道）

- 二值图像

  - 每个像素只有黑白两种颜色的图像，即只有0、1两种取值

- 对比图

  ![](/images/posts/bp/1_compare.jpg)

**1.4 图像在计算机中的存储**

- 存储的是像素点
- 对于彩色图像：每个像素点各有RGB三个通道，每个通道的值都在0-255之间
- 对于灰度图像：可以认为每个像素点只有一个通道，值也在0-255之间
- 对于二值图像：只有0、1两个值

**1.5 如何用图片来训练 & 测试BP神经网络**

- 以本次实验所用的实验数据Mnist数据集为例：包含6w个训练集train样本、1w个测试集test样本；所有的图片都是灰度图；每张图片都有20*20=400个像素点
- 读取图片，读取的是像素值，将每张图片的这400像素点的像素值拉成1行或1列向量存储
- 将BP神经网络输入层的节点数定为400
- BP神经网络每次处理一个样本，即一张图片
- 由此，这400个像素点的像素值便可作为BP神经网络输入层的输入

<br>

### 2. BP神经网络

**2.1 基本概念**

- BP神经网络：向后传播学习的前馈型网络（Back Propagation Feed-forward Neural Network，BPFNN/BPNN ）
- 有监督学习
- 输入层、隐含层、输出层（隐含层可为多个）
- 信号向前传播，误差反向传播
- 反复修正权值和阈值，使得误差值达到最小
- 广泛用于分类，分为训练和测试阶段

**2.2 具有三层结构的BP神经网络**

- 流程图

  ![](/images/posts/bp/1_BP.png)

- 数据 & 参数

  - 训练集输入trainInput、训练集标签trainOutput、测试集输入testInput、测试集testOutput
  - 输入层节点数inNum、隐含层节点数midNum、输出层节点数outNum——i、j、k
  - 输入层与隐含层之间的连接权值Wij、隐含层与输出层之间的连接权值Wjk；阈值b1、b2
  - 学习率θ、收敛误差ε

- 输入层输入X

  - X即一个样本的所有特征值
  - X[i]

- 隐含层输入Hin

  - $$
    Hin[j] = \sum Wij×X[j]  +  b1[j]
    $$

  - 加权和 + 偏置

- 隐含层输出Hout

  - $$
    Hout[j] = f(Hin[j])
    $$

  - f(x)为隐含层的激活函数，这里取
    $$
    f(x) = \frac1{1+e^{-x}}
    $$

- 输出层输入yi

  - $$
    yi[k]=\sum Wjk×Hout[j]  + b2[k]
    $$

  - 加权和 + 偏置

- 输出层输出yn

  - $$
    yn[k]=f(yi[k])
    $$







- f(x)为输出层的激活函数，这里取
  $$
  f(x) = \frac1{1+e^{-x}}
  $$

- 预测误差e

  - $$
    e[k]=yn[k]-trainOutput[k]
    $$

- 总误差E

  - $$
    err[i]=\frac12\sum e[k]^2
    $$

  - $$
    E=\sum err[i]
    $$

  - E可作为算法结束的标志之一

- 输出层误差Eout

  - $$
    Eout[k]=yn[k]×(1-yn[k])×e[k]
    $$

  - yn为输出层输出

- 隐含层误差Emid

  - $$
    Emid[j]=Hout[j]×(1-Hout[j])×\sum Wjk×Eout[k]
    $$

  - Hout为隐含层输出

- 修正权值阈值

  - $$
    Wij = Wij + θ×X[i][j]×Emid[j]
    $$

    

  - $$
    Wjk = Wjk + θ×Hout[j]×Eout[k]
    $$

    

  - $$
    b1[j] = b1[j] + θ×Emid[j]
    $$

    

  - $$
    b2[k] = b2[k] + θ×Eout[k]
    $$







**2.3 Notes**

- 确定各层节点数

  - 输入层节点数：样本的特征数目
  - 隐含层节点数：根据经验公式设定初始值，在后期优化BP神经时，可适当增加节点数以降低网络误差提高精度，但同时也使网络复杂化，从而增加了网络的训练时间和出现过拟合的倾向
  - 输出层节点数：样本的标签（类别）数目

- 算法结束的条件

  - 每次迭代的总误差小于收敛误差
    $$
    E<ε
    $$

  - 达到最大迭代次数

- 优化BP神经网络

  - 适当增加迭代次数
  - 适当增加训练集的样本数目
  - 适当增加隐含层的节点数